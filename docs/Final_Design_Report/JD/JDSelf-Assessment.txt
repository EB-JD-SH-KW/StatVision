For our project, my individual contribution centered around the extraction, transformation, and loading of hundreds of thousands of rows of sports data, ranging from 1870 to 2025. Some other specific tasks I assisted on include building the database context to feed OpenAI API, the general process of turning user queries into real-time results to satisfy the users, and some front-end development, such as the team pages on the website. I also ran the process of launching the site’s EC2 instance and database registration on AWS. Overall, this website taught me more than I could have possibly imagined, as I believe right now, if I had a task for work or class of launching a generic search tool, for say, healthcare data, on an AWS EC2 instance right now, I could probably do it from scratch in memory in just a few days. This was a far cry from how I felt in August.  

Overall, we as a team felt great about the search tool we built, but it didn’t come without obstacles. Using an API to get live up to date sports data in our database is incredibly expensive, as we ran out of tokens well before fully populating the database spending $15-20 a month on API tokens as it is. That meant we had to go other routes than originally planned to populate our database with data, such as finding CSV’s online of others already doing something similar and using their CSV’s to ETL into our database in any case we were permitted to. Thankfully, we found multiple data science websites that allow CSVs for things such as sports data to be taken with a free use policy, so we were able to mitigate most of the damage of our API tokens drying up. 
